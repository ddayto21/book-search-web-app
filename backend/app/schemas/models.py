from pydantic import BaseModel, Field, root_validator, model_validator
from pydantic.json_schema import models_json_schema
from openapi_pydantic.v3 import OpenAPI, Info, PathItem, Operation
from openapi_pydantic.util import PydanticSchema, construct_open_api_with_schema_class

from typing import List, Optional, Literal
import yaml


class Book(BaseModel):
    title: str = Field(
        ...,
        title="Book Title",
        description="The title of the book.",
        example="The 7 Habits of Highly Effective People",
    )
    authors: Optional[List[str]] = Field(
        None,
        title="Authors",
        description="A list of authors.",
        example=["Stephen R. Covey"],
    )
    description: Optional[str] = Field(
        None,
        title="Book Description",
        description="A brief description of the book.",
        example="A classic self-help book.",
    )

    class Config:
        json_schema_extra = {
            "example": {
                "title": "The 7 Habits of Highly Effective People",
                "authors": ["Stephen R. Covey"],
                "description": "A classic self-help book that introduces seven habits for personal and professional effectiveness.",
            }
        }


# Base Message model
class Message(BaseModel):
    """
    Represents a single message in the conversation.
    """

    role: str = Field(
        ...,
        title="Message Role",
        description=(
            "Specifies the role of the message. Allowed values: 'user', 'system', or 'assistant'. "
            "Indicates whether the message was sent by the user, provided by the system, or generated by the assistant."
        ),
        example="user",
    )
    content: str = Field(
        ...,
        title="Message Content",
        description="The actual text content of the message.",
        example="What is the best anime similar to Hunter x Hunter?",
    )

    class Config:
        json_schema_extra = {
            "example": {
                "role": "user",
                "content": "What is the best anime similar to Hunter x Hunter?",
            }
        }


class SystemMessage(BaseModel):
    role: str = Field(
        "system",
        title="System Message Role",
        description="This field is fixed to 'system' for system messages.",
        example="system",
        enum=["system"],
    )
    content: str = Field(
        ...,
        title="System Message Content",
        description="Provides initial instructions or context to set the behavior of the assistant.",
        example="You are a helpful assistant that provides book recommendations and explanations.",
    )

    class Config:
        json_schema_extra = {
            "example": {
                "role": "system",
                "content": "You are a helpful assistant that provides book recommendations and explanations.",
            }
        }


class UserMessage(BaseModel):
    role: str = Field(
        "user",
        title="User Message Role",
        description="This field is fixed to 'user' for user messages.",
        example="user",
        enum=["user"],
    )
    content: str = Field(
        ...,
        title="User Message Content",
        description="Contains the query or input provided by the user.",
        example="What are some good books on personal development?",
    )

    class Config:
        json_schema_extra = {
            "example": {
                "role": "user",
                "content": "What are some good books on personal development?",
            }
        }


class AssistantMessage(BaseModel):
    role: str = Field(
        "assistant",
        title="Assistant Message Role",
        description="This field is fixed to 'assistant' for messages generated by the assistant.",
        example="assistant",
        enum=["assistant"],
    )
    content: str = Field(
        ...,
        title="Assistant Message Content",
        description="Contains the response generated by the language model.",
        example=(
            "I recommend 'The 7 Habits of Highly Effective People' by Stephen R. Covey, "
            "'How to Win Friends & Influence People' by Dale Carnegie, and "
            "'Mindset: The New Psychology of Success' by Carol S. Dweck."
        ),
    )

    class Config:
        json_schema_extra = {
            "example": {
                "role": "assistant",
                "content": (
                    "I recommend 'The 7 Habits of Highly Effective People' by Stephen R. Covey, "
                    "'How to Win Friends & Influence People' by Dale Carnegie, and "
                    "'Mindset: The New Psychology of Success' by Carol S. Dweck."
                ),
            }
        }


# Prompt model combining messages
class Prompt(BaseModel):
    system: SystemMessage = Field(
        ...,
        title="System Message",
        description="Provides initial instructions or context that sets the behavior of the assistant.",
    )
    user: UserMessage = Field(
        ..., title="User Message", description="Contains the user's query or input."
    )
    assistant: Optional[AssistantMessage] = Field(
        None,
        title="Assistant Message",
        description="Contains the assistant's response. This field is optional for requests and is typically populated in responses.",
    )

    class Config:
        json_schema_extra = {
            "example": {
                "system": {
                    "role": "system",
                    "content": "You are a helpful assistant that provides book recommendations and explanations.",
                },
                "user": {
                    "role": "user",
                    "content": "What are some good books on personal development?",
                },
                "assistant": {
                    "role": "assistant",
                    "content": (
                        "1. The 7 Habits of Highly Effective People by Stephen R. Covey\n"
                        "   • Introduces core principles for effectiveness.\n\n"
                        "2. How to Win Friends & Influence People by Dale Carnegie\n"
                        "   • A timeless guide on improving social skills and relationships.\n\n"
                        "3. Mindset: The New Psychology of Success by Carol S. Dweck\n"
                        "   • Explores the benefits of a growth mindset."
                    ),
                },
            }
        }


class MessageHistory(BaseModel):
    """
    Represents the conversation history.
    """

    messages: List[Message] = Field(
        ...,
        title="messages",
        description="A list of chat messages that form the conversation history.",
        example=[
            {
                "role": "user",
                "content": "What is the best anime similar to Hunter x Hunter?",
            }
        ],
    )

    class Config:
        json_schema_extra = {
            "example": {
                "messages": [
                    {
                        "role": "user",
                        "content": "What is the best anime similar to Hunter x Hunter?",
                    }
                ]
            }
        }


# Updated CompletionRequest model with stream field and additional validation.
class CompletionRequest(BaseModel):
    """
    Represents a chat request for the language model (LLM).

    Attributes:
      - model: The identifier for the LLM to use.
      - temperature: Controls the randomness of the generated output.
      - messages: A list of chat messages that form the conversation history.
      - max_tokens: The maximum number of tokens that the model can generate.
      - response_format: Specifies the format of the model's output (e.g., 'json_object').
      - stream: If True, partial message deltas will be sent via SSE.
    """

    model: str = Field(
        "deepseek-chat",
        title="Model Identifier",
        description="The identifier for the language model (e.g., 'deepseek-chat') that will process the conversation.",
        examples=["deepseek-chat", "deepseek-reasoner"],
    )
    temperature: Optional[float] = Field(
        1.3,
        title="Temperature Parameter",
        description=(
            "Controls the randomness of the generated response. Lower values yield more deterministic output, "
            "while higher values increase variability."
        ),
        examples=[0.5, 1.0, 1.3],
    )
    messages: List[Message] = Field(
        ...,
        title="Conversation History",
        description=(
            "A list of chat messages comprising the conversation history so far. "
            "The first message typically contains the user's initial query. Each message must include a role and its content."
        ),
        example=[
            {
                "role": "user",
                "content": "Please produce a JSON output that lists anime similar to Hunter x Hunter.",
            }
        ],
    )
    max_tokens: int = Field(
        1000,
        title="Max Tokens",
        description=(
            "The maximum number of tokens that the model is allowed to generate in response. "
            "Increasing this value may result in longer responses."
        ),
        example=1000,
    )
    response_format: str = Field(
        "json_object",
        title="Response Format",
        description=(
            "Specifies the format of the model's output. For example, setting this to 'json_object' instructs the model "
            "to produce output that is valid JSON. When using 'json_object', at least one user or system message must instruct "
            "the model to produce JSON output (e.g., by including 'json' in the message content)."
        ),
        examples=["text", "json_object"],
    )
    stream: bool = Field(
        False,
        title="Stream",
        description=(
            "If set to True, partial message deltas will be sent as server-sent events (SSE) as they become available, "
            "with the stream terminated by a final 'data: [DONE]' message."
        ),
        example=True,
    )

    @model_validator(mode="before")
    def validate_json_output_instruction(cls, values):
        response_format = values.get("response_format")
        messages = values.get("messages", [])
        if response_format == "json_object":
            instruction_found = any(
                msg.role in ("user", "system")
                and re.search(r"\bjson\b", msg.content, re.IGNORECASE)
                for msg in messages
            )
            if not instruction_found:
                raise ValueError(
                    "When response_format is 'json_object', at least one user or system message must instruct "
                    "the model to produce JSON output (e.g., by including 'json' in the message content)."
                )
        return values

    class Config:
        json_schema_extra = {
            "example": {
                "model": "deepseek-chat",
                "temperature": 1.3,
                "messages": [
                    {
                        "role": "user",
                        "content": "Please produce a JSON output that lists anime similar to Hunter x Hunter. Ensure the output is in json format.",
                    }
                ],
                "max_tokens": 1000,
                "response_format": "json_object",
                "stream": True,
            }
        }


class CompletionResponse(BaseModel):
    """
    Represents the final aggregated response from the language model (LLM) after streaming.

    Streaming Response Details:

    This endpoint returns a streaming response with a content type of `text/event-stream`.
    As tokens become available, partial message deltas are sent as individual SSE events. Each event is formatted as:

    ```
    data: <JSON chunk>\n\n
    ```

    The client is expected to concatenate these chunks into a single aggregated output that matches this schema.
    """

    messages: List[Message] = Field(
        ...,
        title="Response Messages",
        description=(
            "A list of messages returned by the language model, including the assistant's generated response. "
            "For streaming responses, the final aggregated output is expected to conform to this schema."
        ),
        example=[
            {"role": "assistant", "content": "Hello! How can I assist you today?"}
        ],
    )

    class Config:
        json_schema_extra = {
            "example": {
                "messages": [
                    {
                        "role": "assistant",
                        "content": (
                            'data: {"choices": [{"delta": {"content": "Hello", "role": "assistant"}, "finish_reason": null, "index": 0, "logprobs": null}]}\n\n'
                            'data: {"choices": [{"delta": {"content": "!", "role": "assistant"}, "finish_reason": null, "index": 0, "logprobs": null}]}\n\n'
                            "data: [DONE]"
                        ),
                    }
                ]
            }
        }


class Error(BaseModel):
    code: str = Field(
        ...,
        title="Error Code",
        description="An error code representing the type of error.",
        example="404",
    )
    message: str = Field(
        ...,
        title="Error Message",
        description="A detailed message describing the error.",
        example="Not Found",
    )


def construct_base_open_api() -> OpenAPI:
    return OpenAPI(
        openapi="3.1.0",
        info=Info(
            title="Conversational Book Search API",
            version="0.0.1",
        ),
        servers=[
            {"url": "http://localhost:8000", "description": "Local Python server"},
            {"url": "https://api.example.com", "description": "Production server"},
        ],
        paths={
            "/api/chat/stream": {
                "post": Operation(
                    operationId="streamLLM",
                    description="Chat with the language model (LLM) and receive streaming responses.",
                    responses={
                        "200": {
                            "description": "OK, returns a streamed sequence of chat completion chunk objects",
                            "content": {
                                "text/event-stream": {
                                    "schema": PydanticSchema(
                                        schema_class=CompletionResponse
                                    )
                                }
                            },
                        }
                    },
                ).dict()
            }
        },
    )


open_api = construct_base_open_api()
open_api = construct_open_api_with_schema_class(open_api)

if __name__ == "__main__":
    with open("openapi.yaml", "w") as file:
        file.write(
            yaml.dump(
                open_api.model_dump(
                    by_alias=True,
                    mode="json",
                    exclude_none=True,
                    exclude_unset=True,
                ),
                sort_keys=False,
            )
        )
